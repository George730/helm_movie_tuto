# -*- coding: utf-8 -*-
"""Copy of Kafka_AugmentingScript_Combined

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_vCqWt_VgOBgzwyfcm4tOdBnJiL--qj4
"""

import numpy as np
import pandas as pd
import requests
import re
import ast

"""# Set up API Call Functions"""

def get_movie_data(title_year):
  response = requests.get("http://128.2.204.215:8080/movie/" + title_year)
  response_results = response.json()
  return response_results

def get_user_data_from_kafka(user_id):  
  response = requests.get("http://128.2.204.215:8080/user/"+str(int(user_id)))
  response_results = response.json()
  return response_results

def get_keywords_from_api(movie_id):
  response = requests.get("https://api.themoviedb.org/3/movie/"+str(int(movie_id))+"/keywords?api_key=a731ea0ccfac42bffc929317ddc7f94f&query&language=en-US")
  response_results = response.json()
  return response_results

def get_cast_and_crew_from_api(movie_id):
  response = requests.get("https://api.themoviedb.org/3/movie/"+str(int(movie_id))+"/credits?api_key=a731ea0ccfac42bffc929317ddc7f94f&query&language=en-US")
  response_results = response.json()
  return response_results

"""# Read in Data from CSV and Inspect it"""

data=pd.read_csv('kafka_movielog_data.csv', header=None, names = ["DTG","user_id","request"])

#data

"""# Fix the Ugly GET request from Kafka into nice Columns"""

def better_function(row):
  if "/data/" in row["request"]:
    regex_work = re.compile(r'GET /data/m/(.*)/(.*).mpg')
    row["data_or_rate"] = "data"
    regex_search = regex_work.search(row["request"])
    row["title_year"] = regex_search.group(1)
    row["minute_watched"] = regex_search.group(2)
  else:
    regex_work = re.compile(r'GET /rate/(.*)=(?P<user_rating>.*)')
    regex_search = regex_work.search(row["request"])
    row["data_or_rate"] = "rate"
    row["title_year"] = regex_search.group(1)
    row["user_rating"] = regex_search.group(2)
  
  return row

data = data.apply(better_function, axis=1)

data.isnull().sum()

data=data.drop(["request"], axis=1)

#data

"""# Use the Movie Title + Year to look up the Movie ID and get corresponding data from TMDB API"""

def get_movie_data_from_json_to_table(row):
  movie_kafka_json = get_movie_data(row["title_year"])
  print(row["user_id"])
  try:
    row["movie_id"] = movie_kafka_json["tmdb_id"]
    user_kafka_json = get_user_data_from_kafka(row["user_id"])
    keyword_json = get_keywords_from_api(row["movie_id"])
    cast_and_crew_json = get_cast_and_crew_from_api(row["movie_id"])
      
    row["title"] = movie_kafka_json["title"]
    row["overview"] = movie_kafka_json["overview"]
    row["genres"] = movie_kafka_json["genres"]
    row["cast"] = cast_and_crew_json["cast"]
    row["crew"] = cast_and_crew_json["crew"]
    row["keywords"] = keyword_json["keywords"]
    row["popularity"] = movie_kafka_json["popularity"]
    row["release_date"] = movie_kafka_json["release_date"]
    row["runtime"] = movie_kafka_json["runtime"]
    row["vote_average"] = movie_kafka_json["vote_average"]
    row["vote_count"] = movie_kafka_json["vote_count"]
    row["user_age"] = user_kafka_json["age"]
    row["user_occupation"] = user_kafka_json["occupation"]
    row["user_gender"] = user_kafka_json["gender"]
  except:
    pass

  return row

#data=data.head(100)

data = data.apply(get_movie_data_from_json_to_table, axis=1)

print("here")
data.to_csv("10000_augmented_kafka_data.csv", index=False)

data.drop(["title_year"],axis=1)
#data.head()

"""# Get Rid of Any Rows where the movie didn't appear in the TMDB database"""

#-1 in data["movie_id"].value_counts()

data = data[data["movie_id"] != -1]

#-1 in data["movie_id"].value_counts()

"""# Figure out how much metadata about the movies is missing from the TMDB and drop it (could change this if you wanted)"""

data.isnull().sum()

#data.dropna(inplace=True)

"""# Convert the Genre and Keyword Fields into a more readable format"""

#data.iloc[0].genres

def convert_to_more_readable(obj):
    print(obj)
    l=[]
    try:
      for i in obj:
          l.append(i['name'])
    except:
      pass
    return l

data['genres']=data['genres'].apply(convert_to_more_readable)

data['keywords']=data['keywords'].apply(convert_to_more_readable)

#data.head()

"""# Convert the Cast Column into a more readable format"""

data.iloc[0].cast

def getcast(obj):
    l=[]
    counter=0
    try:
      for i in obj:
          if counter!=3:
              l.append(i['name'])
              counter+=1
          else:
              break
    except:
      pass
    return l

data['cast']=data['cast'].apply(getcast)

data.head()

"""# Convert the Crew Column into a more readable format"""

data.iloc[0].crew

def getdir(obj):
    l=[]
    try:
      for i in obj:
          if i['job']=='Director':
              l.append(i['name'])
              break
    except:
      pass
    return l

data['crew']=data['crew'].apply(getdir)

#data.head()

"""# Remove spaces between words in genres, cast, crew, and keywords"""

data['genres']=data['genres'].apply(lambda x: [i.replace(' ','')for i in x])
data['cast']=data['cast'].apply(lambda x: [i.replace(' ','')for i in x])
data['crew']=data['crew'].apply(lambda x: [i.replace(' ','')for i in x])
data['keywords']=data['keywords'].apply(lambda x: [i.replace(' ','')for i in x])

#data.head()

"""# Send it to a CSV"""

data.to_csv("10000_augmented_mediumclean_kafka_data.csv", index=False)

